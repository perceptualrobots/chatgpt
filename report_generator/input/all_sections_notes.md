# Technical Report - PCT Applied (with RL Comparison)
# Generated on: January 05, 2026 at 21:26:22
# Environment: Lunar Lander
# Focus: PCT primary; RL comparator baseline
================================================================================

## ABSTRACT
-----------

[Input file abstract.md not found]

================================================================================

## INTRODUCTION
---------------

# Introduction Notes

## Key Points

- **Control systems** are critical for autonomous agents
- **Traditional control** vs **modern AI approaches**
- **PCT** offers:
  - \citep{powers1973} 
  - Biological inspiration
  - Interpretability
  - Ultra-stability
- **RL** provides data-driven learning capabilities
  - \citep{sutton2018}
- **Research gap**: Direct comparison in standardized environment
- Specific environment provides consistent evaluation platform

================================================================================

## BACKGROUND
-------------

# Background Notes

## Topics to Cover

### Perceptual Control Theory
- **PCT fundamentals**: Simple and powerful hierarchical architecture
  - Self-correcting feedback loop
  - Adapts to environment \citep{powers1973} 

### Optimization & Learning
- **Evolutionary algorithms** for hierarchy optimization
- **Reinforcement learning** theory and deep Q-networks

### Environment
- **Characteristics and challenges**
- Reference: [Lunar Lander Environment](https://gymnasium.farama.org/environments/box2d/lunar_lander/) 
- Reference: Gymnasium platform  \citep{gymnasium2026} 

### Related Work
- Previous comparative studies **limitations**
- Control system **evaluation metrics**

================================================================================

## METHODOLOGY
--------------

# Methodology Notes

## Environment Setup
- **Target environment**: Specify your target environment

## PCT Implementation
- **PCT hierarchy**: Optimally generated by evolutionary algorithm
  - Guided by rewards and specific fitness function
  - The fitness function guiding the evolutionary process was specifically tailored to maximize landing success rates and touchdown velocity, aligning with the primary objectives of the Lunar Lander task.
  - The evolutionary strategy incorporated a varying population size of individuals, with selection pressures applied through tournament selection and crossover operations designed to preserve high-fidelity control strategies.
  - The optimization process iteratively refined the PCT hierarchy over varied generations, yielding a robust controller configuration adaptable to the dynamic conditions of the Lunar Lander environment.

- **Evolutionary algorithm**: DEAP framework with Optuna hyperparameter optimization

## RL Baseline
- **RL approach**: Simphony taken from OpenAI Gym leaderboard \citep{ishuov2024}

## Evaluation
- **Metrics**:
  - Episodes
  - Success rate (out of 100 retries)
  - Number of nodes
  - Number of weights

## Hardware
- **Specs**: This machine (CPU not GPU)

================================================================================

## EXPERIMENTAL RESULTS
-----------------------

# Experimental Results Notes

## Performance Data

### Computational Comparison

The RL controller implements a high-dimensional mapping between state and action a relatively enormous network is necessary as shown in the comparative image where the PCT controller is barely visible. The PCT network, shown in the other image, which dynamically adjusts action to maintain perceptual inputs is just 6 control units and has significantly fewer weights, by a factor of 10,000.

### Visual Media
- **Video** \citep{young2025} : Shows random controller, RL (Symphony) controller, and evolved PCT controller
- **Image**: `RLvPCT-toscale.png`
  - [width=1.0\textwidth]
  - Caption: The RL and PCT networks displayed to scale. The PCT controller is barely visible in comparison.
- **Image**: `PCT.png`
  - Caption: PCT network: 1 level with 6 control units.
  - 6 perceptions simultaneously controlled.
  - The Outputs combine to form environment actions

### Quantitative Results

**Performance comparison **: 100 episodes


| Metric | RL (Symphony) | PCT |
|--------|---------------|-----|
| Total Parameters | 335,622 | 29 |
| Total Nodes | 1,798 | 6 |
| Success Rate (count=100) | 75 | 79 |
| Failure Rate (count=-100) | 5 | 8 |
| Neutral Rate (count=0) | 20 | 13 |

Table: Comparative results for RL and PCT. A score of 100 indicates a successful landing, -100 a crash and 0 is incomplete landing at end of run. The PCT network has significantly fewer weights, by a factor of 10,000.



## Presentation Elements
- Results summary table
- **Results reproduction**:
  - *TODO*: PCT example, link to code
  - Simphony model - \citep{ishuov2024}
- Videos
- Key findings and insights
- Future work will focus on reproducing these results and further exploring the potential of PCT in other dynamic systems.

================================================================================

## DISCUSSION
-------------

# Discussion Notes

## PCT Advantages
- **Interpretability**: Break down into control units
- **Biological plausibility**
- **Psychologically credible**
- **Smaller computational footprint**

## RL Advantages
- **Sample efficiency**
- **Generalization**
- **Scalability**

## Analysis Points
- **Comparative analysis**: Strengths and weaknesses of each approach
    - Furthermore, as PCT is not reliant on large datasets, as is RL, PCT, and its small footprint, is likely to result in superior scalability across diverse environments.
    - 
- **Trade-offs** between approaches
    - Based on this study RL does not provide any advantages over PCT.
- **Implications** for real-world applications
- **Limitations** of current study
    - The exploration of PCT in the Lunar Lander environment is still nascent, and further research is required to fully understand its capabilities and limitations. However, its hierarchical and modular nature suggests PCT is scalable to large and complex environments.
    - The PCT controller is not sensitivity to initial configurations.
- **Unexpected findings** and their explanations

================================================================================

## RECOMMENDATIONS & FUTURE WORK
--------------------------------

# Recommendations & Future Work Notes

## Recommendations

### Hybrid Approaches
- Based on this study there is advantage in combining **PCT and RL**.
- Future research should NOT explore hybrid PCT-RL methodologies.

### Extended Testing
- Testing on more **complex and realistic** world environments
- **Real-world robotics** applications

### Computational Optimization
- Implement **Evolutionary PCT in deep learning framework**
- **Parallel processing** and GPUs

### AI Interpretability
- **Human-interpretable AI systems**
- PCT control systems are inherently interpretable as each unit can be independently examined for what and how its inputs are being controlled.

================================================================================

## REFERENCES
-------------

# References Notes

## Key References to Include

### Perceptual Control Theory

- Powers, W. T., Clark, R., and McFarland, R. (1960). A general feedback theory of human behavior: Part i. *Perceptual and motor skills*, 11(1):71–88.

- Powers, W. T. (1973). *Behavior: The control of perception*. Aldine de Gruyter.

- Young, R. (2017). A General Architecture for Robotics Systems: A Perception-Based Approach to Artificial Life. *Artificial Life*, 23(2):236–286.

- Young, R. (2020). Robotics in the real world: the perceptual control theory approach. In Mansell, W., editor, *The Interdisciplinary Handbook of Perceptual Control Theory*, chapter 14, pages 517–556. Academic Press.

### Reinforcement Learning

- Sutton, R. S., & Barto, A. G. (2018). *Reinforcement Learning: An Introduction*. MIT Press.

- Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A. A., Veness, J., Bellemare, M. G., ... & Hassabis, D. (2015). Human-level control through deep reinforcement learning. *Nature*, 518(7540), 529-533.

### Implementation & Resources

- **Gymnasium. (2026)** Gymnasium Documentation 
  [https://gymnasium.farama.org/](https://gymnasium.farama.org/)

- **Young, R. (2025)** Lunar Lander PCT v. RL  
  [https://www.youtube.com/watch?v=sxW8pNze1Ro](https://www.youtube.com/watch?v=sxW8pNze1Ro)

- **Ishuov, Timur  (2024)** Implementation of Lunar Lander with Symphony  
  - GitHub: [https://github.com/timurgepard/Simphony](https://github.com/timurgepard/Simphony)

================================================================================

