# Methodology Notes

## Environment Setup
- **Target environment**: Specify your target environment

## PCT Implementation
- **PCT hierarchy**: Optimally generated by evolutionary algorithm
  - Guided by rewards and specific fitness function
  - The fitness function guiding the evolutionary process was specifically tailored to maximize landing success rates and touchdown velocity, aligning with the primary objectives of the Lunar Lander task. Specifically, the fitness function minimised 6 variables; the x and y positions and the rotational angle and their velocities, all of which are zero at the landing position.
  - The evolutionary strategy incorporated a varying population size of individuals, with dynamic level and unit counts, with selection pressures applied through tournament selection and crossover operations designed to preserve high-fidelity control strategies.
  - The optimization process iteratively refined the PCT hierarchy over varied generations, yielding a robust controller configuration adaptable to the dynamic conditions of the Lunar Lander environment.

- **Evolutionary algorithm**: DEAP framework with Optuna hyperparameter optimization

## RL Baseline
- **RL approach**: Simphony taken from OpenAI Gym leaderboard \citep{ishuov2024}

## Evaluation
- **Metrics**:
  - Episodes
  - Success rate (out of 100 retries)
  - Number of nodes
  - Number of weights

## Hardware
- **Specs**: This machine (CPU not GPU)

