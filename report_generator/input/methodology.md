# Methodology Notes

## Environment Setup
- **Target environment**: Specify your target environment

## PCT Implementation
- **PCT hierarchy**: Optimally generated by evolutionary algorithm
  - Guided by rewards and specific fitness function
  - The fitness function guiding the evolutionary process was specifically tailored to maximize landing success rates and touchdown velocity, aligning with the primary objectives of the Lunar Lander task.
  - The evolutionary strategy incorporated a varying population size of individuals, with selection pressures applied through tournament selection and crossover operations designed to preserve high-fidelity control strategies.
  - The optimization process iteratively refined the PCT hierarchy over varied generations, yielding a robust controller configuration adaptable to the dynamic conditions of the Lunar Lander environment.

- **Evolutionary algorithm**: DEAP framework with Optuna hyperparameter optimization

## RL Baseline
- **RL approach**: Simphony taken from OpenAI Gym leaderboard \citep{ishuov2024}

## Evaluation
- **Metrics**:
  - Episodes
  - Success rate (out of 100 retries)
  - Number of nodes
  - Number of weights

## Hardware
- **Specs**: This machine (CPU not GPU)

